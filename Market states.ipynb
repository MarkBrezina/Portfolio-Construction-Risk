{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6efc4712-ddb6-4453-96c8-4f21e73fcc29",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48409392-66ee-4afd-873a-fc8569747d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, date, timedelta, timezone\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "import pickle\n",
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a0eec-6850-4554-9fba-20d566ce77df",
   "metadata": {},
   "source": [
    "## Initial - Sign model\n",
    "\n",
    "This model counts the signs of returns on OHLCV for day-by-day. \\\n",
    "It is a crude(simple) model, but has been quite useful elsewhere. \n",
    "\n",
    "It is my belief that expanding on this model can be useful in detecting \"overweights\" of negative or positive returns, and their reversion towards a normal. \\\n",
    "I suspect that there will be a slight overweight of positive to negative signs. Say 52% + and 48% -. Where slightly larger overweights on either side, indicate a market regime of either upwards or downwards trending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebc3b0-9702-4d22-b018-de0822726e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "Y = np.array([[0,0]])\n",
    "\n",
    "for t in [\"BAC\"]:\n",
    "\n",
    "    data = yf.Ticker(t)\n",
    "    data = data.history(start = \"1996-01-01\", end = \"2025-08-15\")\n",
    "    data = data.reset_index(drop = True)\n",
    "    \n",
    "    data = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "\n",
    "    # returns\n",
    "    data['returns'] = data['Close'].diff()/data['Close'].shift(1)\n",
    "    data['returns'].loc[data['returns'].isna()] = 0\n",
    "    \n",
    "    # pn-counter\n",
    "    pos_neg = []\n",
    "    for j in range(len(data)):\n",
    "        if data['returns'][j] >= 0:\n",
    "            pos_neg.append(1)\n",
    "        elif data['returns'][j] < 0:\n",
    "            pos_neg.append(-1)\n",
    "        else:\n",
    "            pos_neg.append(0)\n",
    "    data['PN_counter'] = pos_neg\n",
    "    \n",
    "    \n",
    "    sign_count = [0]\n",
    "    for i in range(1,len(data)):\n",
    "        if i < 2000:\n",
    "            sign_count.append(sum(data['PN_counter'][0:i] * data['Volume'][0:i]) / sum(data['Volume'][0:i]))\n",
    "        else:\n",
    "            sign_count.append(sum(data['PN_counter'][i-2000:i] * data['Volume'][i-2000:i]) / sum(data['Volume'][i-2000:i]))\n",
    "\n",
    "    data[\"sign_count\"] = sign_count\n",
    "\n",
    "    data = data.fillna(0)\n",
    "    data[\"volume-state\"] = data[\"Volume\"].rolling(window=1000).mean()/np.mean(data[\"Volume\"]) - 1\n",
    "    data = data.fillna(0)\n",
    "\n",
    "    #features needed \n",
    "    features = data[[\"sign_count\",\"volume-state\"]][1000:]\n",
    "    features = features.reset_index(drop = True)\n",
    "    \n",
    "    X = np.array(features)\n",
    "    Y = np.concatenate([Y, X])\n",
    "        \n",
    "    lengths.append(len(features))\n",
    "\n",
    "Y = Y[1:]\n",
    "sign_model = GaussianHMM(n_components=3,covariance_type=\"full\",n_iter=1000,random_state=2)\n",
    "sign_model.fit(Y, lengths = lengths)\n",
    "\n",
    "with open(\"sign.pkl\", \"wb\") as f:\n",
    "    pickle.dump(imb_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b6074-f8b0-467e-93f1-a24ff725da4a",
   "metadata": {},
   "source": [
    "## Initial - Volatility model\n",
    "\n",
    "In the above script, exchange the features for volatility, volatility adjusted momentum and ITR.\\\n",
    "These have worked well in our initial tests. But need more accuracy, as well as an additional structural break component.\\\n",
    "The code below can be used to substitute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb3ec1-d3a5-4120-bbbe-adf59ee7655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['volatility'] = data['returns'].rolling(window=20).std()\n",
    "data['VolAdjMomentum'] = data['returns'] / data['volatility']\n",
    "\n",
    "# ITR - interday true range\n",
    "data['ITR'] = (data['High'] - data['Low']) / (data['Open'])\n",
    "data['ITR'].loc[data['ITR'].isna()] = 0\n",
    "data['ITR'][np.isinf(data['ITR'])] = 0\n",
    "\n",
    "\n",
    "#features needed \n",
    "features = data[[\"returns\",\"volatility\", \"VolAdjMomentum\", \"ITR\"]][1000:]\n",
    "features = features.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e3f9d-1e03-42b8-8a33-1a879c99a945",
   "metadata": {},
   "source": [
    "## Initial - returns model\n",
    "Like with the trends in return signs, we have worked to figure out a way to represent changes in the returns distribution. \\\n",
    "In order to find significant changes in the distribution. This has come to some, but not satisfactory results. \\\n",
    "\n",
    "We use multiple returns, shifted on different timeframes along with the sign of the distance of moving averages from the current price. \\\n",
    "the below features are the ones to substitute for our current best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fcb9f-f3ce-4218-8734-60e0989401e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log transform of returns\n",
    "data['log returns'] = log_ret(data['Close'])\n",
    "\n",
    "# Long-term returns\n",
    "data['returns1'] = data['Close'].diff()/data['Close'].shift(21)\n",
    "data['returns1'].loc[data['returns1'].isna()] = 0\n",
    "\n",
    "data['returns3'] = data['Close'].diff()/data['Close'].shift(63)\n",
    "data['returns3'].loc[data['returns3'].isna()] = 0\n",
    "\n",
    "data['returns6'] = data['Close'].diff()/data['Close'].shift(126)\n",
    "data['returns6'].loc[data['returns6'].isna()] = 0\n",
    "\n",
    "data['ma21'] = data['Close'].rolling(window=21).mean()\n",
    "data['ma63'] = data['Close'].rolling(window=63).mean()\n",
    "data['ma126']= data['Close'].rolling(window=126).mean()\n",
    "\n",
    "data[\"sma-s\"] = np.sign(data[\"Close\"] - data[\"ma21\"])\n",
    "data[\"mma-s\"] = np.sign(data[\"Close\"] - data[\"ma63\"])\n",
    "data[\"lma-s\"] = np.sign(data[\"Close\"] - data[\"ma126\"])\n",
    "\n",
    "#features needed \n",
    "features = data[[\"log returns\", \"returns1\",\"returns3\",\"returns6\", \"sma-s\",\"mma-s\",\"lma-s\"]][1000:]\n",
    "features = features.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f900e-d9ae-4bf8-83e2-649e171d50d7",
   "metadata": {},
   "source": [
    "## Initial - Price Model\n",
    "We are not trying to predict the price. We are looking to consider whether the price has bounced outside of an area of confidence. \\\n",
    "This is an extremely simple version, but it has none the less been useful in estimating the rough area for the price at the time.\n",
    "\n",
    "We have substituted with these features for the HMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0930a-c362-4db6-903d-465072ba80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log returns'] = log_ret(data['Close'])\n",
    "\n",
    "data['ma20'] = data['Close'].rolling(window=20).mean()\n",
    "data['ma40'] = data['Close'].rolling(window=40).mean()\n",
    "data['ma120']= data['Close'].rolling(window=120).mean()\n",
    "\n",
    "# Compute MACD line and Signal line\n",
    "data['EMA20'] = data['Close'].ewm(span=20, adjust=False).mean()\n",
    "data['EMA40']  = data['Close'].ewm(span=40, adjust=False).mean()\n",
    "data['EMA120']  = data['Close'].ewm(span=120, adjust=False).mean()\n",
    "\n",
    "data[\"sma-s\"] = np.sign(data[\"Close\"] - data[\"ma20\"])\n",
    "data[\"mma-s\"] = np.sign(data[\"Close\"] - data[\"ma40\"])\n",
    "data[\"lma-s\"] = np.sign(data[\"Close\"] - data[\"ma120\"])\n",
    "\n",
    "data[\"sEma-s\"] = np.sign(data[\"Close\"] - data['EMA20'])\n",
    "data[\"mEma-s\"] = np.sign(data[\"Close\"] - data[\"EMA40\"])\n",
    "data[\"lEma-s\"] = np.sign(data[\"Close\"] - data[\"EMA120\"])\n",
    "\n",
    "#features needed \n",
    "features = data[[\"sma-s\",\"mma-s\",\"lma-s\", \"sEma-s\", \"mEma-s\", \"lEma-s\"]][1000:]\n",
    "features = features.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f778e3-2154-4b73-bf86-400b2259d376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
